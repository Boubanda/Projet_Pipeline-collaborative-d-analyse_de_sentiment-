from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer
from datasets import load_dataset
import torch

# V√©rifier si un GPU est disponible
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üöÄ Training on: {device}")

# Charger le tokenizer BERT
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Charger le dataset IMDb (r√©duit pour entra√Ænement rapide)
dataset = load_dataset("imdb")
train_dataset = dataset["train"].select(range(2000))  # R√©duit √† 2 000 exemples
eval_dataset = dataset["test"].select(range(500))  # R√©duit √† 500 exemples

# Fonction de tokenisation
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Appliquer la tokenisation
train_dataset = train_dataset.map(tokenize_function, batched=True)
eval_dataset = eval_dataset.map(tokenize_function, batched=True)

# Convertir en format `torch.Tensor`
train_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "label"])
eval_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "label"])

def load_model():
    """Charge un mod√®le BERT pr√©-entra√Æn√© pour la classification des sentiments."""
    model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2).to(device)

    training_args = TrainingArguments(
        output_dir="./results",
        eval_strategy="epoch",
        per_device_train_batch_size=1,  # R√©duit pour acc√©l√©rer sur CPU
        per_device_eval_batch_size=1,
        num_train_epochs=1,  # R√©duction √† 1 √©poque
        fp16=torch.cuda.is_available(),
        save_steps=2000,  # Moins de sauvegardes
        weight_decay=0.01,
        logging_dir="./logs",
        logging_steps=2000,  # Moins de logs
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset
    )

    return model, trainer

def train_model():
    """Entra√Æne le mod√®le avec Trainer."""
    model, trainer = load_model()
    print("üöÄ D√©but de l'entra√Ænement du mod√®le...")
    trainer.train()
    print("‚úÖ Entra√Ænement termin√© !")

if __name__ == "__main__":
    train_model()


def train_model():
    """Entra√Æne le mod√®le avec Trainer."""
    model, trainer = load_model()
    print("üöÄ D√©but de l'entra√Ænement du mod√®le...")
    trainer.train()
    print("‚úÖ Entra√Ænement termin√© !")

    # üîπ Sauvegarde du mod√®le et du tokenizer apr√®s entra√Ænement
    model.save_pretrained("models/sentiment_model")
    tokenizer.save_pretrained("models/sentiment_model")

    print("‚úÖ Mod√®le et tokenizer sauvegard√©s avec succ√®s !")

if __name__ == "__main__":
    train_model()
